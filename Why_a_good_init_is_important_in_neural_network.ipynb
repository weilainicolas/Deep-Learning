{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Why a good init is important in neural network",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weilainicolas/Deep-Learning/blob/master/Why_a_good_init_is_important_in_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTCHhfnIAw0j",
        "colab_type": "text"
      },
      "source": [
        "#Why a good init is important\n",
        "To test the impact of init in neural network, I will use matrix multiplication as operations. Will take a input x and weight a. Let x repeatly multiply a and check the mean and std of the output. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtdXTJVAbeH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUvidjJqboHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=torch.randn(100,512)\n",
        "a=torch.randn(512,512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ichj4EZsb9B3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f4245f4-4812-481f-9fb6-270db953b95c"
      },
      "source": [
        "x.mean(), x.std()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.0058), tensor(0.9970))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wnv4VH1b1FF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(100): \n",
        "  x=x@a\n",
        "  if x.std() != x.std(): break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEJCbvAEcANE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "efc21935-b78a-41a2-f438-4f0eb8b750bd"
      },
      "source": [
        "x.mean(),x.std(),i"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(nan), tensor(nan), 27)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOzZcwYRcotT",
        "colab_type": "text"
      },
      "source": [
        "x started as normal distribution with mean=0 and std=1\n",
        "after 27 rounds, mean and std become too big and we lost track of it. Not grad can be calculated in this cast. Thus, cannot train the model\n",
        "\n",
        "Let us reduce the var of a and try again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S97Bt9kvcXdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=torch.randn(100,512)\n",
        "a=torch.randn(512,512)*0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQIUTnOAcbJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(100): \n",
        "  x=x@a\n",
        "  if x.std() != x.std(): break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eefHzqgxcegH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b3605c9-20a6-4093-b8d2-908bcb2b195d"
      },
      "source": [
        "x.mean(), x.std()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-2.0947e+32), tensor(4.1782e+35))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br-s34jbdP5M",
        "colab_type": "text"
      },
      "source": [
        "After 100 rounds, mean and std are 0, which means the outputs are all 0s. cannot train model either in this case. Ideally, we want to initiate a the way that the output would also have mean=0 and std=1. According to [Kaiming's paper](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/He_Delving_Deep_into_ICCV_2015_paper.pdf) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRveI4G9edLs",
        "colab_type": "text"
      },
      "source": [
        "$$Var[y_L]=Var[y_1](\\prod_{l=2}^{L}\\frac{1}{2}n_lVar[a_l])$$\n",
        "\n",
        "However, this is based on relu applied here. Our model have no relu. So we should have:\n",
        "$$Var[y_L]=Var[y_1](\\prod_{l=2}^{L}n_lVar[a_l])$$\n",
        "\n",
        "To have $Var[y_L]=Var[y_1]$, we need to have $\\prod_{l=2}^{L}n_lVar[a_l]=1$\n",
        "\n",
        "This leads to $Var[a_1]=\\frac{1}{n_l}$ \n",
        "$STD[a_1]= \\sqrt{\\frac{1}{n_1}}$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6mTcHRBmITd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srL8hih_lvdt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9c266c0-165f-40ff-aee2-1481c9c71a49"
      },
      "source": [
        "x=torch.randn(512)\n",
        "a=torch.randn(512,512)*math.sqrt(1/512)\n",
        "for i in range(100):\n",
        "  x=a@x\n",
        "x.mean(), x.std() "
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0720), tensor(1.0293))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    }
  ]
}